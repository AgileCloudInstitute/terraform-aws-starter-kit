## Copyright 2020 Green River IT (GreenRiverIT.com) as described in LICENSE.txt distributed with this project on GitHub.  
## Start at https://github.com/AgileCloudInstitute?tab=repositories    

import deploymentFunctions as depfunc
import os
from distutils.dir_util import copy_tree
from pathlib import Path
import platform
import sys

#############################################################################
### Import path locations relative to application root
#############################################################################
app_parent_path = os.path.dirname(os.path.realpath("..\\"))
configAndSecretsPath = app_parent_path+"\\config-and-secrets-outside-app-path\\" 
dirOfYamlFile = configAndSecretsPath + "vars\\yamlInputs\\"
nameOfYamlConfigFile = 'demoConfig.yaml'
nameOfYamlKeysFile = 'keys.yaml'
yamlKeysFileAndPath = dirOfYamlFile + nameOfYamlKeysFile 
pathToApplicationRoot = ''  
tfvarsFileAndPath=''

#############################################################################
### Import variable values, including CLI arguments if from pipeline
#############################################################################
dynamicVarsPath = "" 
if platform.system() == 'Windows':
  dirOfTfvarsFile = app_parent_path+"\\config-and-secrets-outside-app-path\\vars\\VarsForTerraform\\"
  nameOfTfvarsFile = 'keys.tfvars'
  tfvarsFileAndPath = dirOfTfvarsFile + nameOfTfvarsFile
  dynamicVarsPath = configAndSecretsPath + "\\dynamicvars\\"
else:
  #Consider whether to give a separate variable for the name of each secret file, as in the next line, or alternatively to repopulate the same variable each time as shown in the line that follows the next line.  
  tfvarsFileAndPath = '/home/azureuser/' + 'foundationSecrets.tfvars'
  dynamicVarsPath = "/home/azureuser/" + "/dynamicvars/"
#Keep dynamicVarsPath if it exists, but if not exist than create new dynamicVarsPath 
Path(dynamicVarsPath).mkdir(parents=True, exist_ok=True)
ipFileNameAndPath=dynamicVarsPath+"/vmip.txt" 

#The following 7 variables only need to be declared if a pipeline ingests this.  Some of the following will be repopulated by the pipeline inputs.  
keySource=''
yamlConfigFileAndPath = ""
pub = "empty"
sec = "empty"
nameOfYamlConfigFile='demoConfig.yaml'
resourceGroupName="pipeline-resources" 
storageAccountName=''
storageContainerName="tfcontainer"
demoStorageKey=''

#Ingest pipeline variables if they are present
print("len(sys.argv) is: ", len(sys.argv))
if len(sys.argv) > 1:  
  keySource=sys.argv[1]
  if keySource != "keyVault":
    print("keySource is NOT set to a valid value.  ")
  # the build config distributed with this repo put the yaml file in the following location for use by pipelines:
  nameOfYamlConfigFile=sys.argv[2]
  pub=sys.argv[3]
  sec=sys.argv[4]
  storageAccountName=sys.argv[5]
  demoStorageKey=sys.argv[6]
  #Next we make the path to application root depend on the DefaultWorkingDirectory from the pipeline agent.  Assuming a linux agent
  pathToApplicationRoot=sys.argv[7] + '/_terraform-aws-starter-kit/drop/' 
  yamlConfigFileAndPath = pathToApplicationRoot+ nameOfYamlConfigFile
else:  
  keySource = "keyFile"
  yamlConfigFileAndPath = dirOfYamlFile + nameOfYamlConfigFile
  pathToApplicationRoot = os.path.dirname(os.path.realpath(""))

print("Contents of application root directory are: ")
print(*Path(pathToApplicationRoot).iterdir(), sep="\n")

print("keySource is: ", keySource)

params = {
  'resGroupName': resourceGroupName,
  'storageAccountNameTerraformBackend': storageAccountName,
  'storContainerName': storageContainerName,
  'keyFileTF': 'replace-with-autogenerated-key' 
}

#############################################################################
### Functions
#############################################################################
def createTheFoundation(pathToApplicationRoot, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, keySource, pub, sec, **kw):
  foundationInstanceName = depfunc.getFoundationInstanceName(yamlConfigFileAndPath)
  destinationFoundationCallParent = depfunc.convertPathForOS(pathToApplicationRoot, "\\calls-to-modules\\instances\\network-foundation\\")
  destinationFoundationCallInstance = depfunc.instantiateFoundationCallInstance(pathToApplicationRoot, yamlConfigFileAndPath, keySource, demoStorageKey, **kw)
  #############################################################################
  ### Create the network foundation
  #############################################################################
  varsFragmentNet = depfunc.getVarsFragmentFoundation(yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, keySource, pub, sec)
  print("varsFragmentNet is: ", varsFragmentNet)  
  applyCommandNet = "terraform apply -auto-approve" + varsFragmentNet
  print("applyCommandNet is: ", applyCommandNet)
  try: 
    depfunc.runTerraformCommand(applyCommandNet, destinationFoundationCallInstance)
  except NotADirectoryError:
    print("Instance of call to module does not exist, so we will not do anything here now.")
  print("Finished running apply command. ")
  #Finally delete the secrets file fo that the secrets must be retrieved from the key vault every time
  print("About to remove the secrets file. ")
  #Now delete the tfvars file because we only want keys in external locations such as a vault or the yaml input
  os.remove(tfvarsFileAndPath)
  if platform.system() == 'Windows':
    print("You must run the destroyFoundation.py program to destroy all infrastructure you created before you send this back to the git repository.  The reason is that a local Terraform backend is used for this demo so that the instance of the call to module must be retained.  By contrast, when you run this on a Linux agent from a Pipeline, a remote backend will be used to retain Terraform state so that the instance of the call to module can be destroyed at this point when run from a pipeline.  ")
  else:
    depfunc.destroyInstanceOfCallToModule(destinationFoundationCallInstance, destinationFoundationCallParent)

def writeIPFile(ipFileAndPath, vm_ip_pub):
  print("vm_ip_pub is: ", vm_ip_pub)
  ipLine=vm_ip_pub+"\n"	
  print("ipFileAndPath is: ", ipFileAndPath)	
  print("About to write 8 lines to a file.")	
  f = open(ipFileAndPath, "a")	
  f.write(ipLine)	
  f.close()	
  print("About to read the file we just wrote.") 
  f = open(ipFileAndPath, "r") 
  print(f.read())  

def createTheVMs(foundationInstanceName, vmInstanceNames, pathToApplicationRoot, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, ipFile_AndPath, keySource, demoStorageKey, pub, sec, **kw):
  for vmName in vmInstanceNames: 
    print("vmName is; ", vmName)
    destinationVirtualMachineCallInstance = depfunc.instantiateStandaloneVirtualMachineCallInstance(pathToApplicationRoot, yamlConfigFileAndPath, vmName, keySource, demoStorageKey, **kw)
    destinationVirtualMachineCallParent = depfunc.convertPathForOS(pathToApplicationRoot, "\\calls-to-modules\\instances\\vm\\")
    ##############################################################################
    ### Create Virtual Machine and attach to the foundation
    ##############################################################################
    print("depfunc.vpc_id is: ", depfunc.vpc_id) 
    print("depfunc.subnet_id is: ", depfunc.subnet_id) 
    print("depfunc.sg_id is: ", depfunc.sg_id)
    varsFragmentCompute = depfunc.getVarsFragmentVM(yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, depfunc.vpc_id, depfunc.subnet_id, depfunc.sg_id, keySource, pub, sec)
    print("varsFragmentCompute for VM is: ", varsFragmentCompute)
    applyCommandCompute = "terraform apply -auto-approve" + varsFragmentCompute
    print("applyCommandCompute is: ", applyCommandCompute)
    # dirToUseVM = pathToApplicationRoot + "calls-to-modules\\aws-simple-vm-call-to-module\\"
    depfunc.runTerraformCommand(applyCommandCompute, destinationVirtualMachineCallInstance)  
    if depfunc.terraformResult == "Applied": 
      print("Apply operation succeeded for VM.  If it had failed, this block of code would instead automatically quit the program. ")
      #Now record the IP of the VM to a new folder in the application root
      writeIPFile(ipFile_AndPath, depfunc.vm_ip_pub)
      if platform.system() == 'Windows':
        print("You must run the destroyFoundation.py program to destroy all infrastructure you created before you send this back to the git repository.  The reason is that a local Terraform backend is used for this demo so that the instance of the call to module must be retained.  By contrast, when you run this on a Linux agent from a Pipeline, a remote backend will be used to retain Terraform state so that the instance of the call to module can be destroyed at this point when run from a pipeline.  ")
      else:
        #Destroy the instance of the call to module because state is stored in remote Terraform backend
        depfunc.destroyInstanceOfCallToModule(destinationVirtualMachineCallInstance, destinationVirtualMachineCallParent)
    else: 
      quit("Terminating program because the Apply operation failed for a VM in Terraform.")

def createTheSecurityGroupRule(sgr, pathToApplicationRoot, foundationInstanceName, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, vpcId, vpcCidr, sgId, sgName, keySource, demoStorageKey, pub, sec, **kw):
  print("...................................................................................................")
  print("sgr is: ", sgr)
  destinationSecurityGroupRuleCallInstance = depfunc.instantiateSecurityGroupRuleCallInstance(pathToApplicationRoot, yamlConfigFileAndPath, sgr, keySource, demoStorageKey, **kw)
  destinationSecurityGroupRuleCallParent = depfunc.convertPathForOS(pathToApplicationRoot, "\\calls-to-modules\\instances\\security-group-rules\\")
  varsFragmentSG = depfunc.getVarsFragmentSecurityGroup(sgr, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, vpcId, vpcCidr, sgId, sgName, keySource, pub, sec)  
  print("varsFragmentSG is: ", varsFragmentSG)
  print("----------------------------------------------------------------------------------")
  applyCommandSG = "terraform apply -auto-approve" + varsFragmentSG
  print("applyCommandSG is: ", applyCommandSG)
  depfunc.runTerraformCommand(applyCommandSG, destinationSecurityGroupRuleCallInstance)
  if platform.system() == 'Windows':
    print("You must run the destroyFoundation.py program to destroy all infrastructure you created before you send this back to the git repository.  The reason is that a local Terraform backend is used for this demo so that the instance of the call to module must be retained.  By contrast, when you run this on a Linux agent from a Pipeline, a remote backend will be used to retain Terraform state so that the instance of the call to module can be destroyed at this point when run from a pipeline.  ")
  else:
    #Destroy the instance of the call to module because state is stored in remote Terraform backend
    depfunc.destroyInstanceOfCallToModule(destinationSecurityGroupRuleCallInstance, destinationSecurityGroupRuleCallParent)

def createTheBlobStorageInstance(blobStorageInstance, pathToApplicationRoot, foundationInstanceName, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, vpcId, keySource, demoStorageKey, pub, sec, **kw):
  print("Inside createTheBlobStorageInstance(), blobStorageInstance is: ", blobStorageInstance)
  destinationBlobStorageCallInstance = depfunc.instantiateBlobStorageCallInstance(pathToApplicationRoot, yamlConfigFileAndPath, blobStorageInstance, keySource, demoStorageKey, **kw)
  destinationBlobStorageCallParent = depfunc.convertPathForOS(pathToApplicationRoot, "\\calls-to-modules\\instances\\s3-backends\\")
  varsFragmentBlobStorage = depfunc.getVarsFragmentBlobStorage(blobStorageInstance, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, vpcId, keySource, pub, sec)  
  print("varsFragmentBlobStorage is: ", varsFragmentBlobStorage)
  print("----------------------------------------------------------------------------------")
  applyCommandBlobStorage = "terraform apply -auto-approve" + varsFragmentBlobStorage
  print("applyCommandBlobStorage is: ", applyCommandBlobStorage)
  depfunc.runTerraformCommand(applyCommandBlobStorage, destinationBlobStorageCallInstance)
  if platform.system() == 'Windows':
    print("You must run the destroyFoundation.py program to destroy all infrastructure you created before you send this back to the git repository.  The reason is that a local Terraform backend is used for this demo so that the instance of the call to module must be retained.  By contrast, when you run this on a Linux agent from a Pipeline, a remote backend will be used to retain Terraform state so that the instance of the call to module can be destroyed at this point when run from a pipeline.  ")
  else:
    #Destroy the instance of the call to module because state is stored in remote Terraform backend
    depfunc.destroyInstanceOfCallToModule(destinationBlobStorageCallInstance, destinationBlobStorageCallParent)


##############################################################################
### Create Infrastructure By Calling The Functions
##############################################################################
createTheFoundation(pathToApplicationRoot, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, keySource, pub, sec, **params)

# Commenting some of the below during development so that the above can be integrated into the pipeline
if depfunc.terraformResult == "Applied": 
  print("Apply operation succeeded.  Now inside Python conditional block to do only after the Apply operation has succeeded. ")
  ##############################################################################
  ### Copy the template into a new instance of a call to the vm module
  ##############################################################################
  foundationInstanceName = depfunc.getFoundationInstanceName(yamlConfigFileAndPath)
  vmInstanceNames = depfunc.getVirtualMachineInstanceNames(yamlConfigFileAndPath)
  print("vmInstanceNames is: ", vmInstanceNames)
  createTheVMs(foundationInstanceName, vmInstanceNames, pathToApplicationRoot, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, ipFileNameAndPath, keySource, demoStorageKey, pub, sec, **params)
  
  ###############################################################################
  ### Create Security Group Rule and attach to the foundation and VM.  
  ###############################################################################
  sgrInstanceNames = depfunc.getSecurityGroupRuleInstanceNames(yamlConfigFileAndPath) 
  print("sgrInstanceNames is: ", sgrInstanceNames)
  for sgr in sgrInstanceNames:
    createTheSecurityGroupRule(sgr, pathToApplicationRoot, foundationInstanceName, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, depfunc.vpc_id, depfunc.vpc_cidr, depfunc.sg_id, depfunc.sg_name, keySource, demoStorageKey, pub, sec, **params)

  ################################################################################
  ### Create S3 Backend and attach to the foundation
  ################################################################################
  print("For blobStorage: depfunc.vpc_id is: ", depfunc.vpc_id) 
  blobStorageInstanceNames = depfunc.getBlobStorageInstanceNames(yamlConfigFileAndPath)
  print("blobStorageInstanceNames is:", blobStorageInstanceNames)
  for blobStorageInstance in blobStorageInstanceNames:
    createTheBlobStorageInstance(blobStorageInstance, pathToApplicationRoot, foundationInstanceName, yamlConfigFileAndPath, yamlKeysFileAndPath, tfvarsFileAndPath, depfunc.vpc_id, keySource, demoStorageKey, pub, sec, **params)
